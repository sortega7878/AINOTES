{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.0 Further Pre-Processing\n",
    "This notebook does further pre-processing of data to be ready for input into machine learning models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table of Contents\n",
    "[2.1. Setup](#1.)<br>\n",
    "[2.1.1 Loading libraries](#1.1)<br>\n",
    "[2.1.2 Setting data directories](#1.2)<br>\n",
    "[2.1.3 Defining functions](#1.3)<br>\n",
    "\n",
    "[2.2. Further Pre-processing](#2.)<br>\n",
    "[2.2.1 Reading in train, validation, and test data sets](#2.1)<br>\n",
    "[2.2.2 Scaling the spectrograms for min max](#2.2)<br>\n",
    "[2.2.3 Setting genre classes](#2.3)<br>\n",
    "[2.2.4 OPTIONAL: Conversion to 3-channel input](#2.4)<br>\n",
    "[2.2.5 OPTIONAL: Normalization with mean and standard deviation](#2.5)<br>\n",
    "\n",
    "[2.3. Saving Pre-Processed Data](#3.)<br>\n",
    "[2.3.1 Shuffling the data and saving as .npy files](#3.1)<br>\n",
    "[2.3.2 OPTIONAL: No shuffling for embedding and saving as .npy files](#3.2)<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Setup <a class=\"anchor\" id=\"1.\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.1 Loading libraries <a class=\"anchor\" id=\"1.1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import timeit\n",
    "import datetime\n",
    "\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.2 Setting data directories <a class=\"anchor\" id=\"1.2\"></a>\n",
    "V2 edits:\n",
    "* added seed num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory of spectrograms: ./data/spect_subsample_2x10s_np\n"
     ]
    }
   ],
   "source": [
    "ds_description = '2x10s'\n",
    "# Set seed num, if no seed number, set as None\n",
    "ds_seed_num = 'seed119'\n",
    "\n",
    "# Set the directory for the spectrograms\n",
    "data_dir = f'./data/spect_subsample_{ds_description}_np'\n",
    "print(\"Directory of spectrograms: {}\".format(data_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.3 Defining functions <a class=\"anchor\" id=\"1.3\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_dir, ds_description, ds_seed_num, str_X, str_Y):\n",
    "    '''\n",
    "    Loads the .npy data files generated previously from the pre-processing ipynb\n",
    "    Note: .npy files need to be in the format: train_spect_{ds_description}_np.npy\n",
    "    \n",
    "    Inputs\n",
    "    ------\n",
    "    data_dir: directory of the .npy files\n",
    "    ds_description: e.g. '5x10s'  5 subsamples of 10s length\n",
    "    str_X: str name of the 'X' data, either: 'spect' or 'X'\n",
    "    str_Y: str name of the 'Y' data, either: 'labels' or 'Y'\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    6 numpy arrays of:\n",
    "        train_{str_X}, train_{str_Y}, val_{str_X}, val_{str_Y}, test_{str_X}, test_{str_Y}\n",
    "    '''\n",
    "    assert (str_X in ['spect','X']), \"Assertion Error, str_X must be either 'spect' or 'X'.\"\n",
    "    assert (str_Y in ['labels','Y']), \"Assertion Error, str_Y must be either 'labels' or 'Y'.\"\n",
    "    \n",
    "    if ds_seed_num != None:\n",
    "        ds_description_with_seed = f'{ds_description}_{ds_seed_num}'\n",
    "    else:\n",
    "        ds_description_with_seed = f'{ds_description}'\n",
    "    \n",
    "    print(\"Loading .npy data files...\")\n",
    "    # Start timer\n",
    "    start_time = timeit.default_timer()\n",
    "\n",
    "    train_str_X = np.load(f'{data_dir}/train_{str_X}_{ds_description_with_seed}_np.npy')\n",
    "    val_str_X = np.load(f'{data_dir}/val_{str_X}_{ds_description_with_seed}_np.npy')\n",
    "    test_str_X = np.load(f'{data_dir}/test_{str_X}_{ds_description_with_seed}_np.npy')\n",
    "    \n",
    "    if str_Y == 'labels':\n",
    "        train_str_Y = np.load(f'{data_dir}/train_{str_Y}_{ds_description}_np.npy')\n",
    "        val_str_Y = np.load(f'{data_dir}/val_{str_Y}_{ds_description}_np.npy')\n",
    "        test_str_Y = np.load(f'{data_dir}/test_{str_Y}_{ds_description}_np.npy')\n",
    "    else:\n",
    "        train_str_Y = np.load(f'{data_dir}/train_{str_Y}_{ds_description_with_seed}_np.npy')\n",
    "        val_str_Y = np.load(f'{data_dir}/val_{str_Y}_{ds_description_with_seed}_np.npy')\n",
    "        test_str_Y = np.load(f'{data_dir}/test_{str_Y}_{ds_description_with_seed}_np.npy')        \n",
    "    \n",
    "    elapsed = str(datetime.timedelta(seconds = timeit.default_timer() - start_time))\n",
    "    print(\"\", end='\\n')\n",
    "    print(\"Total processing time (h:mm:ss): {}\".format(elapsed[:-7]))\n",
    "    print(\"\\nLoaded .npy data files, verifying shape of saved data...\")\n",
    "    print(f\"Shape of 'train_{str_X}':\", train_str_X.shape)\n",
    "    print(f\"Shape of 'train_{str_Y}':\", train_str_Y.shape)\n",
    "\n",
    "    print(f\"Shape of 'val_{str_X}':\", val_str_X.shape)\n",
    "    print(f\"Shape of 'val_{str_Y}':\", val_str_Y.shape)\n",
    "\n",
    "    print(f\"Shape of 'test_{str_X}':\", test_str_X.shape)\n",
    "    print(f\"Shape of 'test_{str_Y}':\", test_str_Y.shape)\n",
    "    \n",
    "    return train_str_X, train_str_Y, val_str_X, val_str_Y, test_str_X, test_str_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_scaler_3d(array_3d, feature_range=[0,1]):\n",
    "    '''\n",
    "    Takes in a 3D numpy array, converts to 2D to apply scikit-learn's \n",
    "    preprocessing.MinMaxScaler() method, and then converts to 3D\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    3D numpy array with values [0,1] (scaled with MinMaxScaler)    \n",
    "    '''\n",
    "    (s0, s1, s2) = array_3d.shape\n",
    "    array_2d = np.reshape(array_3d, (s0 * s1, s2))\n",
    "    min_max_scaler = preprocessing.MinMaxScaler(feature_range=feature_range)\n",
    "    array_2d = min_max_scaler.fit_transform(array_2d)\n",
    "    array_3d = np.reshape(array_2d, (s0, s1, s2))\n",
    "    \n",
    "    return array_3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_classes(data_labels, class_dict):\n",
    "    '''\n",
    "    Takes in a 1D numpy array of labels, and converts to a 2D array of labels\n",
    "    based on the class_dict\n",
    "    \n",
    "    Inputs\n",
    "    ------\n",
    "    Class_dict: dictionary of int keys starting from 0, and str label values\n",
    "        e.g. genre_dict = {0 : 'Hip-Hop', 1 : 'Pop', 2 : 'Folk',}\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    data_classified: 2D numpy int array of [0,1], 1 indicating the class for the jth location.\n",
    "    '''\n",
    "    # Reverse the dict to have str as the keys\n",
    "    class_dict_reverse = {v:k for k,v in class_dict.items()}\n",
    "    n_obs = len(data_labels)\n",
    "    n_cls = len(class_dict)\n",
    "    data_classified = np.zeros((n_obs, n_cls), dtype=int)\n",
    "    \n",
    "    for i in range(n_obs):\n",
    "        data_classified[i][class_dict_reverse[data_labels[i]]] = 1\n",
    "    \n",
    "    return data_classified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unison_shuffled_copies(a, b):\n",
    "    '''\n",
    "    Shuffles two arrays in unison along the first axis by using a permutation\n",
    "    Returns\n",
    "    -------\n",
    "    a and b numpy arrays shuffled in unison\n",
    "    '''\n",
    "    assert len(a) == len(b)\n",
    "    p = np.random.permutation(len(a))\n",
    "    return a[p], b[p]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Further Preprocessing <a class=\"anchor\" id=\"2.\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.1 Reading in train, validation, and test data sets <a class=\"anchor\" id=\"2.1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading .npy data files...\n",
      "\n",
      "Total processing time (h:mm:ss): 0:00:50\n",
      "\n",
      "Loaded .npy data files, verifying shape of saved data...\n",
      "Shape of 'train_spect': (12788, 431, 128)\n",
      "Shape of 'train_labels': (12788,)\n",
      "Shape of 'val_spect': (1600, 431, 128)\n",
      "Shape of 'val_labels': (1600,)\n",
      "Shape of 'test_spect': (1600, 431, 128)\n",
      "Shape of 'test_labels': (1600,)\n"
     ]
    }
   ],
   "source": [
    "# Read in the spectrogram and labels data from the .npy files\n",
    "train_spect, train_labels, val_spect, val_labels, test_spect, test_labels = load_data(\n",
    "    data_dir, ds_description, ds_seed_num, 'spect', 'labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train [min, max]: [-80.0, 3.814697265625e-06]\n",
      "Val [min, max]: [-80.0, 3.814697265625e-06]\n",
      "Test [min, max]: [-80.0, 3.814697265625e-06]\n"
     ]
    }
   ],
   "source": [
    "# Checking if all train, val, test sets have same min and max ranges\n",
    "print(\"Train [min, max]:\", [train_spect.min(), train_spect.max()])\n",
    "print(\"Val [min, max]:\", [val_spect.min(), val_spect.max()])\n",
    "print(\"Test [min, max]:\", [test_spect.min(), test_spect.max()])\n",
    "\n",
    "assert(train_spect.min() == val_spect.min() == test_spect.min()), 'minimum values do not match'\n",
    "assert(train_spect.max() == val_spect.max() == test_spect.max()), 'maximum values do not match'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.2 Scaling the spectrograms for min max <a class=\"anchor\" id=\"2.2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of 'train_spect': (12788, 431, 128)\n",
      "Train [min, max]: [0.0, 255.0]\n",
      "\n",
      "Shape of 'val_spect': (1600, 431, 128)\n",
      "Val [min, max]: [0.0, 255.00000000000006]\n",
      "\n",
      "Shape of 'test_spect': (1600, 431, 128)\n",
      "Test [min, max]: [0.0, 255.00000000000003]\n"
     ]
    }
   ],
   "source": [
    "# Define the feature range, [0,1] or [0,255]\n",
    "feature_range = [0,255]\n",
    "\n",
    "val_spect_minmax = min_max_scaler_3d(val_spect, feature_range)\n",
    "test_spect_minmax = min_max_scaler_3d(test_spect, feature_range)\n",
    "train_spect_minmax = min_max_scaler_3d(train_spect, feature_range)\n",
    "\n",
    "# Cheecking shape and min and max values\n",
    "print(\"Shape of 'train_spect':\", train_spect_minmax.shape)\n",
    "print(\"Train [min, max]:\", [train_spect_minmax.min(), train_spect_minmax.max()])\n",
    "print()\n",
    "print(\"Shape of 'val_spect':\", val_spect_minmax.shape)\n",
    "print(\"Val [min, max]:\", [val_spect_minmax.min(), val_spect_minmax.max()])\n",
    "print()\n",
    "print(\"Shape of 'test_spect':\", test_spect_minmax.shape)\n",
    "print(\"Test [min, max]:\", [test_spect_minmax.min(), test_spect_minmax.max()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.3 Setting genre classes <a class=\"anchor\" id=\"2.3\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_dict = {0 : 'Hip-Hop',\n",
    "              1 : 'Pop',\n",
    "              2 : 'Folk',\n",
    "              3 : 'Experimental',\n",
    "              4 : 'Rock',\n",
    "              5 : 'International',\n",
    "              6 : 'Electronic',\n",
    "              7 : 'Instrumental'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map labels to classes\n",
    "train_classes = map_classes(train_labels, genre_dict)\n",
    "val_classes = map_classes(val_labels, genre_dict)\n",
    "test_classes = map_classes(test_labels, genre_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.4 OPTIONAL: Conversion to 3-channel input <a class=\"anchor\" id=\"2.4\"></a>\n",
    "V2 edit:\n",
    "* added this for direct feed into pre-trained CNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of 'train_spect': (12788, 431, 128, 3)\n",
      "Train [min, max]: [0.0, 255.0]\n",
      "\n",
      "Shape of 'val_spect': (1600, 431, 128, 3)\n",
      "Val [min, max]: [0.0, 255.00000000000006]\n",
      "\n",
      "Shape of 'test_spect': (1600, 431, 128, 3)\n",
      "Test [min, max]: [0.0, 255.00000000000003]\n"
     ]
    }
   ],
   "source": [
    "train_spect_minmax = np.stack([train_spect_minmax,train_spect_minmax,train_spect_minmax], axis=-1)\n",
    "val_spect_minmax = np.stack([val_spect_minmax,val_spect_minmax,val_spect_minmax], axis=-1)\n",
    "test_spect_minmax = np.stack([test_spect_minmax,test_spect_minmax,test_spect_minmax], axis=-1)\n",
    "\n",
    "print(\"Shape of 'train_spect':\", train_spect_minmax.shape)\n",
    "print(\"Train [min, max]:\", [train_spect_minmax.min(), train_spect_minmax.max()])\n",
    "print()\n",
    "print(\"Shape of 'val_spect':\", val_spect_minmax.shape)\n",
    "print(\"Val [min, max]:\", [val_spect_minmax.min(), val_spect_minmax.max()])\n",
    "print()\n",
    "print(\"Shape of 'test_spect':\", test_spect_minmax.shape)\n",
    "print(\"Test [min, max]:\", [test_spect_minmax.min(), test_spect_minmax.max()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.5 OPTIONAL: Normalization with mean and standard deviation <a class=\"anchor\" id=\"2.5\"></a>\n",
    "V2 edit:\n",
    "* added this but better to rely on preprocess_input from Keras for pre-trained CNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_spect_minmax = (train_spect_minmax - np.mean(train_spect_minmax))/np.std(train_spect_minmax))\n",
    "# val_spect_minmax = (val_spect_minmax - np.mean(val_spect_minmax))/np.std(val_spect_minmax)\n",
    "# test_spect_minmax = (test_spect_minmax - np.mean(test_spect_minmax))/np.std(test_spect_minmax)\n",
    "\n",
    "# print(\"Shape of 'train_spect':\", train_spect_minmax.shape)\n",
    "# print(\"Train [min, max]:\", [train_spect_minmax.min(), train_spect_minmax.max()])\n",
    "# print(\"Train (mean, stdev) :\", [np.mean(train_spect_minmax), np.std(train_spect_minmax)])\n",
    "# print()\n",
    "# print(\"Shape of 'val_spect':\", val_spect_minmax.shape)\n",
    "# print(\"Val [min, max]:\", [val_spect_minmax.min(), val_spect_minmax.max()])\n",
    "# print(\"Val (mean, stdev) :\", [np.mean(val_spect_minmax), np.std(val_spect_minmax)])\n",
    "# print()\n",
    "# print(\"Shape of 'test_spect':\", test_spect_minmax.shape)\n",
    "# print(\"Test [min, max]:\", [test_spect_minmax.min(), test_spect_minmax.max()])\n",
    "# print(\"Test (mean, stdev) :\", [np.mean(test_spect_minmax), np.std(test_spect_minmax)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Saving Pre-Processed Data <a class=\"anchor\" id=\"3.\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.1 Shuffling the data and saving as .npy files<a class=\"anchor\" id=\"3.1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle the data and save the the pre-processed 'X' and 'Y' data files\n",
    "\n",
    "train_X, train_Y = unison_shuffled_copies(train_spect_minmax, train_classes)\n",
    "val_X, val_Y = unison_shuffled_copies(val_spect_minmax, val_classes)\n",
    "test_X, test_Y = unison_shuffled_copies(test_spect_minmax, test_classes)\n",
    "\n",
    "if ds_seed_num != None:\n",
    "    ds_description_with_seed = f'{ds_description}_{ds_seed_num}'\n",
    "else:\n",
    "    ds_description_with_seed = f'{ds_description}'\n",
    "\n",
    "np.save(f'{data_dir}/train_X_{ds_description_with_seed}_np', train_X)\n",
    "np.save(f'{data_dir}/val_X_{ds_description_with_seed}_np', val_X)\n",
    "np.save(f'{data_dir}/test_X_{ds_description_with_seed}_np', test_X)\n",
    "\n",
    "np.save(f'{data_dir}/train_Y_{ds_description_with_seed}_np', train_Y)\n",
    "np.save(f'{data_dir}/val_Y_{ds_description_with_seed}_np', val_Y)\n",
    "np.save(f'{data_dir}/test_Y_{ds_description_with_seed}_np', test_Y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.2 OPTIONAL: No shuffling for embedding and saving as .npy files<a class=\"anchor\" id=\"3.2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# direct saving without shuffling the data.  This is for the embedding set.\n",
    "\n",
    "if ds_seed_num != None:\n",
    "    ds_description_with_seed = f'{ds_description}_{ds_seed_num}'\n",
    "else:\n",
    "    ds_description_with_seed = f'{ds_description}'\n",
    "\n",
    "np.save(f'{data_dir}/train_X_{ds_description_with_seed}_np', train_spect_minmax)\n",
    "np.save(f'{data_dir}/val_X_{ds_description_with_seed}_np', val_spect_minmax)\n",
    "np.save(f'{data_dir}/test_X_{ds_description_with_seed}_np', test_spect_minmax)\n",
    "\n",
    "np.save(f'{data_dir}/train_Y_{ds_description_with_seed}_np', train_classes)\n",
    "np.save(f'{data_dir}/val_Y_{ds_description_with_seed}_np', val_classes)\n",
    "np.save(f'{data_dir}/test_Y_{ds_description_with_seed}_np', test_classes)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
